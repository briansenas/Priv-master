{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CLASIFICACIÓN DEL RIESGO DE ABANDONO DE LOS CLIENTES DE UN BANCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos con el que vamos a trabajar ahora contiene información sobre los usuarios de un banco. Queremos predecir si los clientes van a dejar de usar los servicios de dicho banco o no. El conjunto de datos consta de 10000 observaciones y 14 variables.\n",
    "\n",
    "La siguiente figura indica cómo cargar el conjunto de Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una matriz con las variables de entrada y otra matriz con la variable de salida (objetivo, columna 14). Excluiremos la columna 1 y 2 que son ‘row_number’ y ‘customerid’ ya que no nos aportan información útil para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,3:13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', 41, 1, 83807.86, 1, 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', 42, 8, 159660.8, 3, 1, 0, 113931.57],\n",
       "       [699, 'France', 'Female', 39, 1, 0.0, 2, 0, 0, 93826.63]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer el análisis más sencillo si codificamos las variables no numéricas. Country contiene los valores: ’France, Spain, Germany’ y Gender: ‘Male, Female’. La manera de codificarlo será convertir estas palabras a valores numéricos. Para esto usaremos la función LabelEncoder, de la librería ‘ScikitLearn’, que al darle una cadena de texto nos devuelve valores entre 0 y n_clases-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
       "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
       "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
       "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
       "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que Country ahora toma valores del 0 al 2 mientras que male y female fueron reemplazados por 0 y 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la función train_test_split de la librería ScikitLearn para dividir nuestros datos.\n",
    "\n",
    "Usaremos 80% para entrenar el modelo y 20% para validarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[696, 0, 1, ..., 0, 0, 126353.13],\n",
       "        [635, 2, 1, ..., 1, 1, 60739.16],\n",
       "        [585, 1, 1, ..., 1, 1, 112333.22],\n",
       "        ...,\n",
       "        [742, 0, 0, ..., 1, 1, 180066.59],\n",
       "        [802, 1, 0, ..., 0, 1, 169183.66],\n",
       "        [774, 2, 0, ..., 0, 0, 108804.28]], dtype=object),\n",
       " array([[794, 1, 0, ..., 1, 0, 160526.36],\n",
       "        [624, 0, 0, ..., 1, 0, 168002.31],\n",
       "        [759, 0, 1, ..., 0, 1, 121409.06],\n",
       "        ...,\n",
       "        [589, 1, 0, ..., 1, 1, 143022.31],\n",
       "        [652, 2, 1, ..., 0, 1, 170025.43],\n",
       "        [565, 0, 0, ..., 1, 1, 168303.55]], dtype=object),\n",
       " array([1, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 1, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si observamos los datos detenidamente podemos apreciar que hay variables cuyos valores pueden\n",
    "ser muy variados, desde muy altos a muy pequeños por esta razón escalaremos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.47570015, -0.90354823,  0.9171678 , ..., -1.55196866,\n",
       "         -1.03227043,  0.44797438],\n",
       "        [-0.15694707,  1.51074229,  0.9171678 , ...,  0.64434291,\n",
       "          0.9687384 , -0.69291758],\n",
       "        [-0.67551037,  0.30359703,  0.9171678 , ...,  0.64434291,\n",
       "          0.9687384 ,  0.20419699],\n",
       "        ...,\n",
       "        [ 0.95277839, -0.90354823, -1.09031302, ...,  0.64434291,\n",
       "          0.9687384 ,  1.38194096],\n",
       "        [ 1.57505435,  0.30359703, -1.09031302, ..., -1.55196866,\n",
       "          0.9687384 ,  1.19270919],\n",
       "        [ 1.2846589 ,  1.51074229, -1.09031302, ..., -1.55196866,\n",
       "         -1.03227043,  0.14283598]]),\n",
       " array([[ 1.49208422,  0.30359703, -1.09031302, ...,  0.64434291,\n",
       "         -1.03227043,  1.04217655],\n",
       "        [-0.271031  , -0.90354823, -1.09031302, ...,  0.64434291,\n",
       "         -1.03227043,  1.17216794],\n",
       "        [ 1.12908991, -0.90354823,  0.9171678 , ..., -1.55196866,\n",
       "          0.9687384 ,  0.36200717],\n",
       "        ...,\n",
       "        [-0.63402531,  0.30359703, -1.09031302, ...,  0.64434291,\n",
       "          0.9687384 ,  0.73781713],\n",
       "        [ 0.01936445,  1.51074229,  0.9171678 , ..., -1.55196866,\n",
       "          0.9687384 ,  1.20734584],\n",
       "        [-0.88293569, -0.90354823, -1.09031302, ...,  0.64434291,\n",
       "          0.9687384 ,  1.17740589]]),\n",
       " array([1, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 1, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez escalados los datos, pasamos a construir la red neuronal. Importamos Keras, usamos el módulo Sequential para inicializar la red y el modelo Dense para añadir capas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mcarm\\anaconda3\\envs\\MASTER24\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos la red con Sequential()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mcarm\\anaconda3\\envs\\MASTER24\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos las capas usando la función Dense. Indicamos el número de nodos que queremos añadir con output_dim, Init es la inicialización del descenso de gradiente estocástico. Los pesos iniciales serán una variable aleatoria uniforme. Input_dim sólo es necesaria en la primera capa para que el modelo sepa la cantidad de variables que va a recibir, en nuestro caso 11. A partir de aquí las siguientes capas heredarán esta cualidad de la primera capa. La función de activación que utilizaremos será relu en las dos primeras capas (cuanto más cerca tenga su valor a 1, la neurona estará más activada y tendrá más interacción) y en la capa final hemos utilizado la función sigmoide ya que nuestro objetivo es clasificar.\n",
    "\n",
    "Una vez que tenemos la configuración específica de la red, la siguiente tarea es compilarla, para eso utilizamos la función Compile. El primer argumento de esta función es Optimizer que indica el método para entrenar los pesos. Adam es un algoritmo que se basa en el cálculo del descenso del Gradiente Estocástico. El segundo parámetro es loss, este usará la función ‘binary_crossentropy’ para clasificar en 2 categorías. Si tuviéramos más categorías utilizaríamos la función ‘categorical_crossentropy’. Para saber la bondad de nuestra red neuronal utilizaremos la métrica accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(6, activation = 'relu', input_shape = (10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mcarm\\anaconda3\\envs\\MASTER24\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la función fit para ajustar los pesos de la red. Batch_size para especificar el número de observaciones que necesita entrenar antes de actualizar los pesos. Epoch nos indica el número de iteraciones que realizaremos en el entrenamiento. La estimación de estos parámetros se tiene que hacer por ensayo-error, probando con diferentes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\mcarm\\anaconda3\\envs\\MASTER24\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mcarm\\anaconda3\\envs\\MASTER24\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8000/8000 [==============================] - 7s 778us/step - loss: 0.4490 - accuracy: 0.8060\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 6s 781us/step - loss: 0.3904 - accuracy: 0.8378\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 6s 785us/step - loss: 0.3655 - accuracy: 0.8497\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3576 - accuracy: 0.8512\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 6s 789us/step - loss: 0.3520 - accuracy: 0.8543\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 6s 790us/step - loss: 0.3495 - accuracy: 0.8566\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3488 - accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 6s 789us/step - loss: 0.3487 - accuracy: 0.8559\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 6s 792us/step - loss: 0.3475 - accuracy: 0.8559\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3469 - accuracy: 0.8583\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 6s 783us/step - loss: 0.3456 - accuracy: 0.8589\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 6s 780us/step - loss: 0.3432 - accuracy: 0.8595\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3422 - accuracy: 0.8615\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.3416 - accuracy: 0.8587\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 6s 782us/step - loss: 0.3405 - accuracy: 0.8609\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 6s 767us/step - loss: 0.3396 - accuracy: 0.8589\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 6s 782us/step - loss: 0.3386 - accuracy: 0.8585\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 6s 768us/step - loss: 0.3392 - accuracy: 0.8608\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 6s 775us/step - loss: 0.3383 - accuracy: 0.8615\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 6s 775us/step - loss: 0.3382 - accuracy: 0.8621\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 6s 772us/step - loss: 0.3370 - accuracy: 0.8626\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 6s 772us/step - loss: 0.3379 - accuracy: 0.8614\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 6s 772us/step - loss: 0.3362 - accuracy: 0.8631\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 6s 769us/step - loss: 0.3373 - accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.3373 - accuracy: 0.8619\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 6s 778us/step - loss: 0.3358 - accuracy: 0.8605\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 6s 768us/step - loss: 0.3376 - accuracy: 0.8634\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 6s 765us/step - loss: 0.3364 - accuracy: 0.8612\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 6s 775us/step - loss: 0.3345 - accuracy: 0.8595\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 6s 775us/step - loss: 0.3359 - accuracy: 0.8621\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 6s 768us/step - loss: 0.3364 - accuracy: 0.8644\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 6s 770us/step - loss: 0.3341 - accuracy: 0.8609\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.3344 - accuracy: 0.8640\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 6s 768us/step - loss: 0.3354 - accuracy: 0.8637\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 6s 765us/step - loss: 0.3347 - accuracy: 0.8622\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 6s 776us/step - loss: 0.3343 - accuracy: 0.8634\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 6s 778us/step - loss: 0.3349 - accuracy: 0.8635\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.3348 - accuracy: 0.8639\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 6s 769us/step - loss: 0.3341 - accuracy: 0.8596\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.3340 - accuracy: 0.8636\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 6s 777us/step - loss: 0.3334 - accuracy: 0.8629\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 6s 783us/step - loss: 0.3335 - accuracy: 0.8608\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 6s 786us/step - loss: 0.3338 - accuracy: 0.8599\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3338 - accuracy: 0.8636\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3338 - accuracy: 0.8610\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 6s 802us/step - loss: 0.3342 - accuracy: 0.8604\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 6s 780us/step - loss: 0.3340 - accuracy: 0.8641\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.3343 - accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 6s 792us/step - loss: 0.3337 - accuracy: 0.8618\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 6s 783us/step - loss: 0.3340 - accuracy: 0.8605\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3329 - accuracy: 0.8636\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 6s 768us/step - loss: 0.3328 - accuracy: 0.8622\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3325 - accuracy: 0.8621\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 6s 791us/step - loss: 0.3333 - accuracy: 0.8627\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 6s 771us/step - loss: 0.3333 - accuracy: 0.8625\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 6s 773us/step - loss: 0.3320 - accuracy: 0.8619\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 6s 786us/step - loss: 0.3336 - accuracy: 0.8651\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 6s 779us/step - loss: 0.3322 - accuracy: 0.8655\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.3328 - accuracy: 0.8640\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3334 - accuracy: 0.8636\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 6s 777us/step - loss: 0.3333 - accuracy: 0.8616\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3329 - accuracy: 0.8635\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3335 - accuracy: 0.8631\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 6s 798us/step - loss: 0.3325 - accuracy: 0.8622\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 6s 796us/step - loss: 0.3326 - accuracy: 0.8640\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3330 - accuracy: 0.8641\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 6s 784us/step - loss: 0.3329 - accuracy: 0.8627\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 6s 783us/step - loss: 0.3336 - accuracy: 0.8627\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 6s 790us/step - loss: 0.3326 - accuracy: 0.8646\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 6s 800us/step - loss: 0.3332 - accuracy: 0.8626\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3318 - accuracy: 0.8655\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 6s 800us/step - loss: 0.3327 - accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 6s 800us/step - loss: 0.3328 - accuracy: 0.8631\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 6s 795us/step - loss: 0.3326 - accuracy: 0.8651\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 6s 781us/step - loss: 0.3324 - accuracy: 0.8631\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 6s 792us/step - loss: 0.3321 - accuracy: 0.8611\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 6s 781us/step - loss: 0.3318 - accuracy: 0.8634\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3321 - accuracy: 0.8645\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3318 - accuracy: 0.8636\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 6s 785us/step - loss: 0.3322 - accuracy: 0.8627\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 6s 777us/step - loss: 0.3326 - accuracy: 0.8654\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 6s 795us/step - loss: 0.3315 - accuracy: 0.8626\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 6s 782us/step - loss: 0.3327 - accuracy: 0.8622\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 6s 787us/step - loss: 0.3323 - accuracy: 0.8648\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 6s 791us/step - loss: 0.3323 - accuracy: 0.8644\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 6s 793us/step - loss: 0.3318 - accuracy: 0.8633\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 6s 789us/step - loss: 0.3319 - accuracy: 0.8651\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 6s 786us/step - loss: 0.3324 - accuracy: 0.8640\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 6s 791us/step - loss: 0.3322 - accuracy: 0.8635\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 6s 788us/step - loss: 0.3314 - accuracy: 0.8625\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 6s 801us/step - loss: 0.3327 - accuracy: 0.8640\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 6s 810us/step - loss: 0.3324 - accuracy: 0.8633\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 6s 791us/step - loss: 0.3324 - accuracy: 0.8612\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 6s 791us/step - loss: 0.3318 - accuracy: 0.8673\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 6s 795us/step - loss: 0.3316 - accuracy: 0.8639\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 6s 790us/step - loss: 0.3318 - accuracy: 0.8625\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 6s 780us/step - loss: 0.3317 - accuracy: 0.8643\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 6s 782us/step - loss: 0.3323 - accuracy: 0.8646\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 6s 801us/step - loss: 0.3311 - accuracy: 0.8636\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 6s 782us/step - loss: 0.3318 - accuracy: 0.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2961c3e6090>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la predicción sobre nuestro conjunto de test lo haremos mediante la siguiente expresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 756us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción nos proporcionará la probabilidad de pertenecer a un grupo u otro, de tal manera que aquellos valores mayores que 0.5 serán 1 y el resto 0.\n",
    "\n",
    "Creamos una matriz de confusión y vemos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1518,   86],\n",
       "       [ 214,  182]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      1604\n",
      "           1       0.68      0.46      0.55       396\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.70      0.73      2000\n",
      "weighted avg       0.84      0.85      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Búsqueda del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:,3:13].values\n",
    "y = dataset.iloc[:,13].values\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.6.1\n",
      "Uninstalling scikit-learn-1.6.1:\n",
      "  Successfully uninstalled scikit-learn-1.6.1\n",
      "Collecting scikit-learn==1.5.2\n",
      "  Using cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn==1.5.2) (1.15.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.10/site-packages (from scikit-learn==1.5.2) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn==1.5.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn==1.5.2) (3.5.0)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To be able to import the sklear-wrapper\n",
    "# !pip install scikeras\n",
    "# !pip uninstall -y scikit-learn\n",
    "# !pip install scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 862, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 433, in _build_keras_model\n    model = final_build_fn(**build_params)\n  File \"/tmp/ipykernel_2333713/1338524737.py\", line 21, in get_model\n    model.add(Input(10))\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py\", line 191, in Input\n    layer = InputLayer(\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py\", line 92, in __init__\n    shape = backend.standardize_shape(shape)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/keras/src/backend/common/variables.py\", line 562, in standardize_shape\n    raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nValueError: Cannot convert '10' to a shape.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(optimizer\u001b[38;5;241m=\u001b[39moptimizers)\n\u001b[1;32m     58\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39msk_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 1501, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 770, in fit\n    self._fit(\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 925, in _fit\n    X, y = self._initialize(X, y)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 862, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/scikeras/wrappers.py\", line 433, in _build_keras_model\n    model = final_build_fn(**build_params)\n  File \"/tmp/ipykernel_2333713/1338524737.py\", line 21, in get_model\n    model.add(Input(10))\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py\", line 191, in Input\n    layer = InputLayer(\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py\", line 92, in __init__\n    shape = backend.standardize_shape(shape)\n  File \"/home/briansenas/Master/SoftComputing/Optimizacion/guiones/Guion 2-20250110/.venv/lib/python3.10/site-packages/keras/src/backend/common/variables.py\", line 562, in standardize_shape\n    raise ValueError(f\"Cannot convert '{shape}' to a shape.\")\nValueError: Cannot convert '10' to a shape.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import Sequential\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(140421)\n",
    "keras.utils.set_random_seed(140421)\n",
    "\n",
    "def get_model(\n",
    "  optimizer = None,\n",
    "  activation=\"relu\",\n",
    "  layer_config = None,\n",
    "):\n",
    "  if not layer_config:\n",
    "    layer_config = [(32, 0.1), (64, .2), (32, .2)]\n",
    "  if not optimizer:\n",
    "    optimizer = lambda: keras.optimizers.RMSprop()\n",
    "  optimizer = optimizer()\n",
    "  model = Sequential()\n",
    "  model.add(Input(10))\n",
    "  for layer in layer_config:\n",
    "    model.add(Dense(layer[0], activation=activation))\n",
    "    if len(layer) > 0 and layer[1] > 0.0:\n",
    "      model.add(Dropout(layer[1]))\n",
    "  model.add(Dense(1, activation=\"sigmoid\"))\n",
    "  return model\n",
    "\n",
    "fit_params = {\n",
    "  \"callbacks\": [\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(),\n",
    "  ]\n",
    "}\n",
    "\n",
    "# sk_model = KerasClassifier(build_fn=get_model)\n",
    "sk_model = KerasClassifier(\n",
    "    get_model,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "      \"accuracy\"\n",
    "#       keras.metrics.F1Score(),\n",
    "#       keras.metrics.Recall(),\n",
    "#       keras.metrics.Precision(),\n",
    "#       keras.metrics.Accuracy()\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizers = [\n",
    "  lambda: keras.optimizers.AdamW(\n",
    "    learning_rate=keras.optimizers.schedules.ExponentialDecay()\n",
    "  ),\n",
    "]\n",
    "activation = [\"relu\", \"leaky_relu\", \"tanh\"]\n",
    "epochs = 20\n",
    "batches = [1, 16, 32]\n",
    "param_grid = dict(optimizer=optimizers)\n",
    "grid = GridSearchCV(estimator=sk_model, param_grid=param_grid, refit=False, cv=3, scoring=\"accuracy\")\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
